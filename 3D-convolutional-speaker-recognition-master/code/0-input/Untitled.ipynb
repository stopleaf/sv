{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--file_path FILE_PATH]\n",
      "                             [--audio_dir AUDIO_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\stopleaf\\AppData\\Roaming\\jupyter\\runtime\\kernel-a2d86395-a44b-40b8-87bc-a665058affb2.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\sv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.io.wavfile import read\n",
    "import scipy.io.wavfile as wav\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from random import shuffle\n",
    "import speechpy\n",
    "import datetime\n",
    "\n",
    "\n",
    "######################################\n",
    "####### Define the dataset class #####\n",
    "######################################\n",
    "class AudioDataset():\n",
    "    \"\"\"Audio dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, files_path, audio_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            files_path (string): Path to the .txt file which the address of files are saved in it.\n",
    "            root_dir (string): Directory with all the audio files.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # self.sound_files = [x.strip() for x in content]\n",
    "        self.audio_dir = audio_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Open the .txt file and create a list from each line.\n",
    "        with open(files_path, 'r') as f:\n",
    "            content = f.readlines()\n",
    "        # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "        list_files = []\n",
    "        for x in content:\n",
    "            sound_file_path = os.path.join(self.audio_dir, x.strip().split()[1])\n",
    "            try:\n",
    "                with open(sound_file_path, 'rb') as f:\n",
    "                    riff_size, _ = wav._read_riff_chunk(f)\n",
    "                    file_size = os.path.getsize(sound_file_path)\n",
    "\n",
    "                # Assertion error.\n",
    "                assert riff_size == file_size and os.path.getsize(sound_file_path) > 1000, \"Bad file!\"\n",
    "\n",
    "                # Add to list if file is OK!\n",
    "                list_files.append(x.strip())\n",
    "            except OSError as err:\n",
    "                print(\"OS error: {0}\".format(err))\n",
    "            except ValueError:\n",
    "                print('file %s is corrupted!' % sound_file_path)\n",
    "            # except:\n",
    "            #     print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            #     raise\n",
    "\n",
    "        # Save the correct and healthy sound files to a list.\n",
    "        self.sound_files = list_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sound_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the sound file path\n",
    "        sound_file_path = os.path.join(self.audio_dir, self.sound_files[idx].split()[1])\n",
    "\n",
    "        ##############################\n",
    "        ### Reading and processing ###\n",
    "        ##############################\n",
    "\n",
    "        # Reading .wav file\n",
    "        fs, signal = wav.read(sound_file_path)\n",
    "\n",
    "        # Reading .wav file\n",
    "        import soundfile as sf\n",
    "        signal, fs = sf.read(sound_file_path)\n",
    "\n",
    "        ###########################\n",
    "        ### Feature Extraction ####\n",
    "        ###########################\n",
    "\n",
    "        # DEFAULTS:\n",
    "        num_coefficient = 40\n",
    "\n",
    "        # Staching frames\n",
    "        frames = speechpy.processing.stack_frames(signal, sampling_frequency=fs, frame_length=0.025,\n",
    "                                                  frame_stride=0.01,\n",
    "                                                  zero_padding=True)\n",
    "\n",
    "        # # Extracting power spectrum (choosing 3 seconds and elimination of DC)\n",
    "        power_spectrum = speechpy.processing.power_spectrum(frames, fft_points=2 * num_coefficient)[:, 1:]\n",
    "\n",
    "        logenergy = speechpy.feature.lmfe(signal, sampling_frequency=fs, frame_length=0.025, frame_stride=0.01,\n",
    "                                          num_filters=num_coefficient, fft_length=1024, low_frequency=0,\n",
    "                                          high_frequency=None)\n",
    "\n",
    "        ########################\n",
    "        ### Handling sample ####\n",
    "        ########################\n",
    "\n",
    "        # Label extraction\n",
    "        label = int(self.sound_files[idx].split()[0])\n",
    "\n",
    "        sample = {'feature': logenergy, 'label': label}\n",
    "\n",
    "        ########################\n",
    "        ### Post Processing ####\n",
    "        ########################\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        else:\n",
    "            feature, label = sample['feature'], sample['label']\n",
    "            sample = feature, label\n",
    "\n",
    "        return sample\n",
    "        # return sample\n",
    "\n",
    "\n",
    "class CMVN(object):\n",
    "    \"\"\"Cepstral mean variance normalization.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label']\n",
    "\n",
    "        # Mean variance normalization of the spectrum.\n",
    "        # The following line should be Uncommented if cepstral mean variance normalization is desired!\n",
    "        # feature = speechpy.processing.cmvn(feature, variance_normalization=True)\n",
    "\n",
    "        return {'feature': feature, 'label': label}\n",
    "\n",
    "class Feature_Cube(object):\n",
    "    \"\"\"Return a feature cube of desired size.\n",
    "\n",
    "    Args:\n",
    "        cube_shape (tuple): The shape of the feature cube.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cube_shape, augmentation=True):\n",
    "        assert isinstance(cube_shape, (tuple))\n",
    "        self.augmentation = augmentation\n",
    "        self.cube_shape = cube_shape\n",
    "        self.num_utterances = cube_shape[0]\n",
    "        self.num_frames = cube_shape[1]\n",
    "        self.num_coefficient = cube_shape[2]\n",
    "\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label']\n",
    "\n",
    "        # Feature cube.\n",
    "        feature_cube = np.zeros((self.num_utterances, self.num_frames, self.num_coefficient), dtype=np.float32)\n",
    "\n",
    "        if self.augmentation:\n",
    "            # Get some random starting point for creation of the future cube of size (num_frames x num_coefficient x num_utterances)\n",
    "            # Since we are doing random indexing, the data augmentation is done as well because in each iteration it returns another indexing!\n",
    "            idx = np.random.randint(feature.shape[0] - self.num_frames, size=self.num_utterances)\n",
    "            for num, index in enumerate(idx):\n",
    "                feature_cube[num, :, :] = feature[index:index + self.num_frames, :]\n",
    "        else:\n",
    "            idx = range(self.num_utterances)\n",
    "            for num, index in enumerate(idx):\n",
    "                feature_cube[num, :, :] = feature[index:index + self.num_frames, :]\n",
    "\n",
    "\n",
    "\n",
    "        # return {'feature': feature_cube, 'label': label}\n",
    "        return {'feature': feature_cube[None, :, :, :], 'label': label}\n",
    "\n",
    "\n",
    "class ToOutput(object):\n",
    "    \"\"\"Return the output.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label']\n",
    "\n",
    "        feature, label = sample['feature'], sample['label']\n",
    "        return feature, label\n",
    "\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> Compose([\n",
    "        >>>     CMVN(),\n",
    "        >>>     Feature_Cube(cube_shape=(20, 80, 40),\n",
    "        >>>     augmentation=True), ToOutput(),\n",
    "        >>>        ])\n",
    "        If necessary, for the details of this class, please refer to Pytorch documentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # add parser\n",
    "    parser = argparse.ArgumentParser(description='Input pipeline')\n",
    "\n",
    "    # The text file in which the paths to the audio files are available.\n",
    "    # The path are relative to the directory of the audio files\n",
    "    # Format of each line of the txt file is \"class_label subject_dir/sound_file_name.ext\"\n",
    "    # Example of each line: 0 subject/sound.wav\n",
    "    parser.add_argument('--file_path',\n",
    "                        default=os.path.expanduser(\n",
    "                            '~/github/3D-convolutional-speaker-recognition/code/0-input/file_path.txt'),\n",
    "                        help='The file names for development phase')\n",
    "\n",
    "    # The directory of the audio files separated by subject\n",
    "    parser.add_argument('--audio_dir',\n",
    "                        default=os.path.expanduser('~/github/3D-convolutional-speaker-recognition/code/0-input/Audio'),\n",
    "                        help='Location of sound files')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    dataset = AudioDataset(files_path=args.file_path, audio_dir=args.audio_dir,\n",
    "                           transform=Compose([CMVN(), Feature_Cube(cube_shape=(20, 80, 40), augmentation=True), ToOutput()]))\n",
    "   \n",
    "    # idx is the representation of the batch size which chosen to be as one sample (index) from the data.\n",
    "    # ex: batch_features = [dataset.__getitem__(idx)[0] for idx in range(32)] \n",
    "    # The batch_features is a list and len(batch_features)=32.\n",
    "    idx = 0\n",
    "    feature, label = dataset.__getitem__(idx)\n",
    "    print(feature.shape)\n",
    "    print(label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sv",
   "language": "python",
   "name": "sv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
