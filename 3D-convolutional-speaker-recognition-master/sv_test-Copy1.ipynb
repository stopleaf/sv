{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\python36.zip', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\DLLs', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\lib', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv', '', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\lib\\\\site-packages', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\stopleaf\\\\.ipython', 'D:\\\\sv\\x03D-convolutional-speaker-recognition-master\\\\code\\x01-development\\nets']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('D:\\sv\\3D-convolutional-speaker-recognition-master\\code\\1-development\\nets')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\python36.zip', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\DLLs', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\lib', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv', '', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\lib\\\\site-packages', 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\sv\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\stopleaf\\\\.ipython', 'D:\\\\sv\\x03D-convolutional-speaker-recognition-master']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--file_path FILE_PATH]\n",
      "                             [--audio_dir AUDIO_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\stopleaf\\AppData\\Roaming\\jupyter\\runtime\\kernel-e7dc0847-eea8-40a0-b016-4c539b5ceb99.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\sv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.io.wavfile import read\n",
    "import scipy.io.wavfile as wav\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from random import shuffle\n",
    "import speechpy\n",
    "import datetime\n",
    "\n",
    "\n",
    "######################################\n",
    "####### Define the dataset class #####\n",
    "######################################\n",
    "class AudioDataset():\n",
    "    \"\"\"Audio dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, files_path, audio_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            files_path (string): Path to the .txt file which the address of files are saved in it.\n",
    "            root_dir (string): Directory with all the audio files.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # self.sound_files = [x.strip() for x in content]\n",
    "        self.audio_dir = audio_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Open the .txt file and create a list from each line.\n",
    "        with open(files_path, 'r') as f:\n",
    "            content = f.readlines()\n",
    "        # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "        list_files = []\n",
    "        for x in content:\n",
    "            sound_file_path = os.path.join(self.audio_dir, x.strip().split()[1])\n",
    "            try:\n",
    "                with open(sound_file_path, 'rb') as f:\n",
    "                    riff_size, _ = wav._read_riff_chunk(f)\n",
    "                    file_size = os.path.getsize(sound_file_path)\n",
    "\n",
    "                # Assertion error.\n",
    "                assert riff_size == file_size and os.path.getsize(sound_file_path) > 1000, \"Bad file!\"\n",
    "\n",
    "                # Add to list if file is OK!\n",
    "                list_files.append(x.strip())\n",
    "            except OSError as err:\n",
    "                print(\"OS error: {0}\".format(err))\n",
    "            except ValueError:\n",
    "                print('file %s is corrupted!' % sound_file_path)\n",
    "            # except:\n",
    "            #     print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            #     raise\n",
    "\n",
    "        # Save the correct and healthy sound files to a list.\n",
    "        self.sound_files = list_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sound_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the sound file path\n",
    "        sound_file_path = os.path.join(self.audio_dir, self.sound_files[idx].split()[1])\n",
    "\n",
    "        ##############################\n",
    "        ### Reading and processing ###\n",
    "        ##############################\n",
    "\n",
    "        # Reading .wav file\n",
    "        fs, signal = wav.read(sound_file_path)\n",
    "\n",
    "        # Reading .wav file\n",
    "        import soundfile as sf\n",
    "        signal, fs = sf.read(sound_file_path)\n",
    "\n",
    "        ###########################\n",
    "        ### Feature Extraction ####\n",
    "        ###########################\n",
    "\n",
    "        # DEFAULTS:\n",
    "        num_coefficient = 40\n",
    "\n",
    "        # Staching frames\n",
    "        frames = speechpy.processing.stack_frames(signal, sampling_frequency=fs, frame_length=0.025,\n",
    "                                                  frame_stride=0.01,\n",
    "                                                  zero_padding=True)\n",
    "\n",
    "        # # Extracting power spectrum (choosing 3 seconds and elimination of DC)\n",
    "        power_spectrum = speechpy.processing.power_spectrum(frames, fft_points=2 * num_coefficient)[:, 1:]\n",
    "\n",
    "        logenergy = speechpy.feature.lmfe(signal, sampling_frequency=fs, frame_length=0.025, frame_stride=0.01,\n",
    "                                          num_filters=num_coefficient, fft_length=1024, low_frequency=0,\n",
    "                                          high_frequency=None)\n",
    "\n",
    "        ########################\n",
    "        ### Handling sample ####\n",
    "        ########################\n",
    "\n",
    "        # Label extraction\n",
    "        label = int(self.sound_files[idx].split()[0])\n",
    "\n",
    "        sample = {'feature': logenergy, 'label': label}\n",
    "\n",
    "        ########################\n",
    "        ### Post Processing ####\n",
    "        ########################\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        else:\n",
    "            feature, label = sample['feature'], sample['label']\n",
    "            sample = feature, label\n",
    "\n",
    "        return sample\n",
    "        # return sample\n",
    "\n",
    "\n",
    "class CMVN(object):\n",
    "    \"\"\"Cepstral mean variance normalization.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label']\n",
    "\n",
    "        # Mean variance normalization of the spectrum.\n",
    "        # The following line should be Uncommented if cepstral mean variance normalization is desired!\n",
    "        # feature = speechpy.processing.cmvn(feature, variance_normalization=True)\n",
    "\n",
    "        return {'feature': feature, 'label': label}\n",
    "\n",
    "class Feature_Cube(object):\n",
    "    \"\"\"Return a feature cube of desired size.\n",
    "\n",
    "    Args:\n",
    "        cube_shape (tuple): The shape of the feature cube.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cube_shape, augmentation=True):\n",
    "        assert isinstance(cube_shape, (tuple))\n",
    "        self.augmentation = augmentation\n",
    "        self.cube_shape = cube_shape\n",
    "        self.num_utterances = cube_shape[0]\n",
    "        self.num_frames = cube_shape[1]\n",
    "        self.num_coefficient = cube_shape[2]\n",
    "\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label']\n",
    "\n",
    "        # Feature cube.\n",
    "        feature_cube = np.zeros((self.num_utterances, self.num_frames, self.num_coefficient), dtype=np.float32)\n",
    "\n",
    "        if self.augmentation:\n",
    "            # Get some random starting point for creation of the future cube of size (num_frames x num_coefficient x num_utterances)\n",
    "            # Since we are doing random indexing, the data augmentation is done as well because in each iteration it returns another indexing!\n",
    "            idx = np.random.randint(feature.shape[0] - self.num_frames, size=self.num_utterances)\n",
    "            for num, index in enumerate(idx):\n",
    "                feature_cube[num, :, :] = feature[index:index + self.num_frames, :]\n",
    "        else:\n",
    "            idx = range(self.num_utterances)\n",
    "            for num, index in enumerate(idx):\n",
    "                feature_cube[num, :, :] = feature[index:index + self.num_frames, :]\n",
    "\n",
    "\n",
    "\n",
    "        # return {'feature': feature_cube, 'label': label}\n",
    "        return {'feature': feature_cube[None, :, :, :], 'label': label}\n",
    "\n",
    "\n",
    "class ToOutput(object):\n",
    "    \"\"\"Return the output.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label']\n",
    "\n",
    "        feature, label = sample['feature'], sample['label']\n",
    "        return feature, label\n",
    "\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> Compose([\n",
    "        >>>     CMVN(),\n",
    "        >>>     Feature_Cube(cube_shape=(20, 80, 40),\n",
    "        >>>     augmentation=True), ToOutput(),\n",
    "        >>>        ])\n",
    "        If necessary, for the details of this class, please refer to Pytorch documentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # add parser\n",
    "    parser = argparse.ArgumentParser(description='Input pipeline')\n",
    "\n",
    "    # The text file in which the paths to the audio files are available.\n",
    "    # The path are relative to the directory of the audio files\n",
    "    # Format of each line of the txt file is \"class_label subject_dir/sound_file_name.ext\"\n",
    "    # Example of each line: 0 subject/sound.wav\n",
    "    parser.add_argument('--file_path',\n",
    "                        default=os.path.expanduser(\n",
    "                            '~/github/3D-convolutional-speaker-recognition/code/0-input/file_path.txt'),\n",
    "                        help='The file names for development phase')\n",
    "\n",
    "    # The directory of the audio files separated by subject\n",
    "    parser.add_argument('--audio_dir',\n",
    "                        default=os.path.expanduser('~/github/3D-convolutional-speaker-recognition/code/0-input/Audio'),\n",
    "                        help='Location of sound files')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    dataset = AudioDataset(files_path=args.file_path, audio_dir=args.audio_dir,\n",
    "                           transform=Compose([CMVN(), Feature_Cube(cube_shape=(20, 80, 40), augmentation=True), ToOutput()]))\n",
    "   \n",
    "    # idx is the representation of the batch size which chosen to be as one sample (index) from the data.\n",
    "    # ex: batch_features = [dataset.__getitem__(idx)[0] for idx in range(32)] \n",
    "    # The batch_features is a list and len(batch_features)=32.\n",
    "    idx = 0\n",
    "    feature, label = dataset.__getitem__(idx)\n",
    "    print(feature.shape)\n",
    "\n",
    "    print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6de77e549a10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnets_factory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mroc_curve\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcalculate_roc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nets'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "import tables\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "import random\n",
    "from nets import nets_factory\n",
    "from auxiliary import losses\n",
    "from roc_curve import calculate_roc\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "######################\n",
    "# Train Directory #\n",
    "######################\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'train_dir', '../../results/TRAIN_CNN_3D/train_logs',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'development_dataset_path', '../../data/development_sample_dataset_speaker.hdf5',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_clones', 3,\n",
    "                            'Number of model clones to deploy.')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('clone_on_cpu', False,\n",
    "                            'Use CPUs to deploy clones.')\n",
    "tf.app.flags.DEFINE_boolean('online_pair_selection', False,\n",
    "                            'Use online pair selection.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('worker_replicas', 1, 'Number of worker replicas.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_ps_tasks', 0,\n",
    "    'The number of parameter servers. If the value is 0, then the parameters '\n",
    "    'are handled locally by the worker.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_readers', 8,\n",
    "    'The number of parallel readers that read data from the dataset.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_preprocessing_threads', 8,\n",
    "    'The number of threads used to create the batches.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'log_every_n_steps', 1,\n",
    "    'The frequency with which logs are print.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'save_summaries_secs', 10,\n",
    "    'The frequency with which summaries are saved, in seconds.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'save_interval_secs', 500,\n",
    "    'The frequency with which the model is saved, in seconds.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'task', 0, 'Task id of the replica running the training.')\n",
    "\n",
    "######################\n",
    "# Optimization Flags #\n",
    "######################\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'weight_decay', 0.00004, 'The weight decay on the model weights.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'optimizer', 'adam',\n",
    "    'The name of the optimizer, one of \"adadelta\", \"adagrad\", \"adam\",'\n",
    "    '\"ftrl\", \"momentum\", \"sgd\" or \"rmsprop\".')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'adadelta_rho', 0.95,\n",
    "    'The decay rate for adadelta.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'adagrad_initial_accumulator_value', 0.1,\n",
    "    'Starting value for the AdaGrad accumulators.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'adam_beta1', 0.9,\n",
    "    'The exponential decay rate for the 1st moment estimates.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'adam_beta2', 0.999,\n",
    "    'The exponential decay rate for the 2nd moment estimates.')\n",
    "\n",
    "tf.app.flags.DEFINE_float('opt_epsilon', 1.0, 'Epsilon term for the optimizer.')\n",
    "\n",
    "tf.app.flags.DEFINE_float('ftrl_learning_rate_power', -0.5,\n",
    "                          'The learning rate power.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'ftrl_initial_accumulator_value', 0.1,\n",
    "    'Starting value for the FTRL accumulators.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'ftrl_l1', 0.0, 'The FTRL l1 regularization strength.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'ftrl_l2', 0.0, 'The FTRL l2 regularization strength.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'momentum', 0.9,\n",
    "    'The momentum for the MomentumOptimizer and RMSPropOptimizer.')\n",
    "\n",
    "tf.app.flags.DEFINE_float('rmsprop_momentum', 0.9, 'Momentum.')\n",
    "\n",
    "tf.app.flags.DEFINE_float('rmsprop_decay', 0.9, 'Decay term for RMSProp.')\n",
    "\n",
    "#######################\n",
    "# Learning Rate Flags #\n",
    "#######################\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'learning_rate_decay_type',\n",
    "    'exponential',\n",
    "    'Specifies how the learning rate is decayed. One of \"fixed\", \"exponential\",'\n",
    "    ' or \"polynomial\"')\n",
    "\n",
    "tf.app.flags.DEFINE_float('learning_rate', 10.0, 'Initial learning rate.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'end_learning_rate', 0.0001,\n",
    "    'The minimal end learning rate used by a polynomial decay learning rate.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'label_smoothing', 0.0, 'The amount of label smoothing.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'learning_rate_decay_factor', 0.94, 'Learning rate decay factor.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'num_epochs_per_decay', 5.0,\n",
    "    'Number of epochs after which learning rate decays.')\n",
    "\n",
    "tf.app.flags.DEFINE_bool(\n",
    "    'sync_replicas', False,\n",
    "    'Whether or not to synchronize the replicas during training.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'replicas_to_aggregate', 1,\n",
    "    'The Number of gradients to collect before updating params.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'moving_average_decay', None,\n",
    "    'The decay to use for the moving average.'\n",
    "    'If left as None, then moving averages are not used.')\n",
    "\n",
    "#######################\n",
    "# Dataset Flags #\n",
    "#######################\n",
    "\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'model_speech', 'cnn_speech', 'The name of the architecture to train.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'batch_size', 3, 'The number of samples in each batch. It will be the number of samples distributed for all clones.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_epochs', 1, 'The number of epochs for training.')\n",
    "\n",
    "# Store all elemnts in FLAG structure!\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "def _configure_learning_rate(num_samples_per_epoch, global_step):\n",
    "    \"\"\"Configures the learning rate.\n",
    "\n",
    "    Args:\n",
    "      num_samples_per_epoch: The number of samples in each epoch of training.\n",
    "      global_step: The global_step tensor.\n",
    "\n",
    "    Returns:\n",
    "      A `Tensor` representing the learning rate.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: if\n",
    "    \"\"\"\n",
    "    decay_steps = int(num_samples_per_epoch / FLAGS.batch_size *\n",
    "                      FLAGS.num_epochs_per_decay)\n",
    "    if FLAGS.sync_replicas:\n",
    "        decay_steps /= FLAGS.replicas_to_aggregate\n",
    "\n",
    "    if FLAGS.learning_rate_decay_type == 'exponential':\n",
    "        return tf.train.exponential_decay(FLAGS.learning_rate,\n",
    "                                          global_step,\n",
    "                                          decay_steps,\n",
    "                                          FLAGS.learning_rate_decay_factor,\n",
    "                                          staircase=True,\n",
    "                                          name='exponential_decay_learning_rate')\n",
    "    elif FLAGS.learning_rate_decay_type == 'fixed':\n",
    "        return tf.constant(FLAGS.learning_rate, name='fixed_learning_rate')\n",
    "    elif FLAGS.learning_rate_decay_type == 'polynomial':\n",
    "        return tf.train.polynomial_decay(FLAGS.learning_rate,\n",
    "                                         global_step,\n",
    "                                         decay_steps,\n",
    "                                         FLAGS.end_learning_rate,\n",
    "                                         power=1.0,\n",
    "                                         cycle=False,\n",
    "                                         name='polynomial_decay_learning_rate')\n",
    "    else:\n",
    "        raise ValueError('learning_rate_decay_type [%s] was not recognized',\n",
    "                         FLAGS.learning_rate_decay_type)\n",
    "\n",
    "\n",
    "def _configure_optimizer(learning_rate):\n",
    "    \"\"\"Configures the optimizer used for training.\n",
    "\n",
    "    Args:\n",
    "      learning_rate: A scalar or `Tensor` learning rate.\n",
    "\n",
    "    Returns:\n",
    "      An instance of an optimizer.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: if FLAGS.optimizer is not recognized.\n",
    "    \"\"\"\n",
    "    if FLAGS.optimizer == 'adadelta':\n",
    "        optimizer = tf.train.AdadeltaOptimizer(\n",
    "            learning_rate,\n",
    "            rho=FLAGS.adadelta_rho,\n",
    "            epsilon=FLAGS.opt_epsilon)\n",
    "    elif FLAGS.optimizer == 'adagrad':\n",
    "        optimizer = tf.train.AdagradOptimizer(\n",
    "            learning_rate,\n",
    "            initial_accumulator_value=FLAGS.adagrad_initial_accumulator_value)\n",
    "    elif FLAGS.optimizer == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate,\n",
    "            beta1=FLAGS.adam_beta1,\n",
    "            beta2=FLAGS.adam_beta2,\n",
    "            epsilon=FLAGS.opt_epsilon)\n",
    "    elif FLAGS.optimizer == 'ftrl':\n",
    "        optimizer = tf.train.FtrlOptimizer(\n",
    "            learning_rate,\n",
    "            learning_rate_power=FLAGS.ftrl_learning_rate_power,\n",
    "            initial_accumulator_value=FLAGS.ftrl_initial_accumulator_value,\n",
    "            l1_regularization_strength=FLAGS.ftrl_l1,\n",
    "            l2_regularization_strength=FLAGS.ftrl_l2)\n",
    "    elif FLAGS.optimizer == 'momentum':\n",
    "        optimizer = tf.train.MomentumOptimizer(\n",
    "            learning_rate,\n",
    "            momentum=FLAGS.momentum,\n",
    "            name='Momentum')\n",
    "    elif FLAGS.optimizer == 'rmsprop':\n",
    "        optimizer = tf.train.RMSPropOptimizer(\n",
    "            learning_rate,\n",
    "            decay=FLAGS.rmsprop_decay,\n",
    "            momentum=FLAGS.rmsprop_momentum,\n",
    "            epsilon=FLAGS.opt_epsilon)\n",
    "    elif FLAGS.optimizer == 'sgd':\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    else:\n",
    "        raise ValueError('Optimizer [%s] was not recognized', FLAGS.optimizer)\n",
    "    return optimizer\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "\n",
    "    Note that this function provides a synchronization point across all towers.\n",
    "\n",
    "    Args:\n",
    "      tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "        is over individual gradients. The inner list is over the gradient\n",
    "        calculation for each tower.\n",
    "    Returns:\n",
    "       List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "       across all towers.\n",
    "    \"\"\"\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads\n",
    "\n",
    "\n",
    "# Load the sample artificial dataset\n",
    "fileh = tables.open_file(FLAGS.development_dataset_path, mode='r')\n",
    "\n",
    "##################################\n",
    "######### Check dataset ##########\n",
    "##################################\n",
    "\n",
    "# Train\n",
    "print(\"Train data shape:\", fileh.root.utterance_train.shape)\n",
    "print(\"Train label shape:\", fileh.root.label_train.shape)\n",
    "\n",
    "# Test\n",
    "print(\"Test data shape:\", fileh.root.utterance_test.shape)\n",
    "print(\"Test label shape:\",fileh.root.label_test.shape)\n",
    "\n",
    "# Get the number of subjects\n",
    "num_subjects = len(np.unique(fileh.root.label_train[:]))\n",
    "\n",
    "#################################\n",
    "####### Main function ###########\n",
    "#################################\n",
    "def main(_):\n",
    "\n",
    "    # Log\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default(), tf.device('/cpu:0'):\n",
    "\n",
    "        #########################################\n",
    "        ########## required from data ###########\n",
    "        #########################################\n",
    "        num_samples_per_epoch = fileh.root.label_train.shape[0]\n",
    "        num_batches_per_epoch = int(num_samples_per_epoch / FLAGS.batch_size)\n",
    "\n",
    "        num_samples_per_epoch_test = fileh.root.label_test.shape[0]\n",
    "        num_batches_per_epoch_test = int(num_samples_per_epoch_test / FLAGS.batch_size)\n",
    "\n",
    "        # Create global_step\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "        #####################################\n",
    "        #### Configure the larning rate. ####\n",
    "        #####################################\n",
    "        learning_rate = _configure_learning_rate(num_samples_per_epoch, global_step)\n",
    "        opt = _configure_optimizer(learning_rate)\n",
    "\n",
    "        ######################\n",
    "        # Select the network #\n",
    "        ######################\n",
    "\n",
    "        # Training flag.\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        # Get the network. The number of subjects is num_subjects.\n",
    "        model_speech_fn = nets_factory.get_network_fn(\n",
    "            FLAGS.model_speech,\n",
    "            num_classes=num_subjects,\n",
    "            weight_decay=FLAGS.weight_decay,\n",
    "            is_training=is_training)\n",
    "\n",
    "\n",
    "        #####################################\n",
    "        # Select the preprocessing function #\n",
    "        #####################################\n",
    "\n",
    "        # TODO: Do some preprocessing if necessary.\n",
    "\n",
    "        ##############################################################\n",
    "        # Create a dataset provider that loads data from the dataset #\n",
    "        ##############################################################\n",
    "        # with tf.device(deploy_config.inputs_device()):\n",
    "        \"\"\"\n",
    "        Define the place holders and creating the batch tensor.\n",
    "        \"\"\"\n",
    "        speech = tf.placeholder(tf.float32, (20, 80, 40, 1))\n",
    "        label = tf.placeholder(tf.int32, (1))\n",
    "        batch_dynamic = tf.placeholder(tf.int32, ())\n",
    "        margin_imp_tensor = tf.placeholder(tf.float32, ())\n",
    "\n",
    "        # Create the batch tensors\n",
    "        batch_speech, batch_labels = tf.train.batch(\n",
    "            [speech, label],\n",
    "            batch_size=batch_dynamic,\n",
    "            num_threads=FLAGS.num_preprocessing_threads,\n",
    "            capacity=5 * FLAGS.batch_size)\n",
    "\n",
    "        #############################\n",
    "        # Specify the loss function #\n",
    "        #############################\n",
    "        tower_grads = []\n",
    "        with tf.variable_scope(tf.get_variable_scope()):\n",
    "            for i in range(FLAGS.num_clones):\n",
    "                with tf.device('/gpu:%d' % i):\n",
    "                    with tf.name_scope('%s_%d' % ('tower', i)) as scope:\n",
    "                        \"\"\"\n",
    "                        Two distance metric are defined:\n",
    "                           1 - distance_weighted: which is a weighted average of the distance between two structures.\n",
    "                           2 - distance_l2: which is the regular l2-norm of the two networks outputs.\n",
    "                        Place holders\n",
    "                        \"\"\"\n",
    "\n",
    "                        ########################################\n",
    "                        ######## Outputs of two networks #######\n",
    "                        ########################################\n",
    "\n",
    "                        # Distribute data among all clones equally.\n",
    "                        step = int(FLAGS.batch_size / float(FLAGS.num_clones))\n",
    "\n",
    "                        # Network outputs.\n",
    "                        logits, end_points_speech = model_speech_fn(batch_speech[i * step: (i + 1) * step])\n",
    "\n",
    "\n",
    "                        ###################################\n",
    "                        ########## Loss function ##########\n",
    "                        ###################################\n",
    "                        # one_hot labeling\n",
    "                        label_onehot = tf.one_hot(tf.squeeze(batch_labels[i * step : (i + 1) * step], [1]), depth=num_subjects, axis=-1)\n",
    "\n",
    "                        SOFTMAX = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_onehot)\n",
    "\n",
    "                        # Define loss\n",
    "                        with tf.name_scope('loss'):\n",
    "                            loss = tf.reduce_mean(SOFTMAX)\n",
    "\n",
    "                        # Accuracy\n",
    "                        with tf.name_scope('accuracy'):\n",
    "                            # Evaluate the model\n",
    "                            correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(label_onehot, 1))\n",
    "\n",
    "                            # Accuracy calculation\n",
    "                            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "                        # ##### call the optimizer ######\n",
    "                        # # TODO: call optimizer object outside of this gpu environment\n",
    "                        #\n",
    "                        # Reuse variables for the next tower.\n",
    "                        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                        # Calculate the gradients for the batch of data on this CIFAR tower.\n",
    "                        grads = opt.compute_gradients(loss)\n",
    "\n",
    "                        # Keep track of the gradients across all towers.\n",
    "                        tower_grads.append(grads)\n",
    "\n",
    "        # We must calculate the mean of each gradient. Note that this is the\n",
    "        # synchronization point across all towers.\n",
    "        grads = average_gradients(tower_grads)\n",
    "\n",
    "        # Apply the gradients to adjust the shared variables.\n",
    "        apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "        # Track the moving averages of all trainable variables.\n",
    "        MOVING_AVERAGE_DECAY = 0.9999\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(\n",
    "            MOVING_AVERAGE_DECAY, global_step)\n",
    "        variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "        # Group all updates to into a single train op.\n",
    "        train_op = tf.group(apply_gradient_op, variables_averages_op)\n",
    "\n",
    "        #################################################\n",
    "        ########### Summary Section #####################\n",
    "        #################################################\n",
    "\n",
    "        # Gather initial summaries.\n",
    "        summaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))\n",
    "\n",
    "        # Add summaries for all end_points.\n",
    "        for end_point in end_points_speech:\n",
    "            x = end_points_speech[end_point]\n",
    "            summaries.add(tf.summary.scalar('sparsity/' + end_point,\n",
    "                                            tf.nn.zero_fraction(x)))\n",
    "\n",
    "        # Add summaries for variables.\n",
    "        for variable in slim.get_model_variables():\n",
    "            summaries.add(tf.summary.histogram(variable.op.name, variable))\n",
    "\n",
    "        # Add to parameters to summaries\n",
    "        summaries.add(tf.summary.scalar('learning_rate', learning_rate))\n",
    "        summaries.add(tf.summary.scalar('global_step', global_step))\n",
    "        summaries.add(tf.summary.scalar('eval/Loss', loss))\n",
    "        summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES))\n",
    "\n",
    "        # Merge all summaries together.\n",
    "        summary_op = tf.summary.merge(list(summaries), name='summary_op')\n",
    "\n",
    "    ###########################\n",
    "    ######## Training #########\n",
    "    ###########################\n",
    "\n",
    "    with tf.Session(graph=graph, config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "\n",
    "        # Initialization of the network.\n",
    "        variables_to_restore = slim.get_variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore, max_to_keep=20)\n",
    "        coord = tf.train.Coordinator()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        # op to write logs to Tensorboard\n",
    "        summary_writer = tf.summary.FileWriter(FLAGS.train_dir, graph=graph)\n",
    "\n",
    "        #####################################\n",
    "        ############## TRAIN ################\n",
    "        #####################################\n",
    "\n",
    "        step = 1\n",
    "        for epoch in range(FLAGS.num_epochs):\n",
    "\n",
    "            # Loop over all batches\n",
    "            for batch_num in range(num_batches_per_epoch):\n",
    "                step += 1\n",
    "                start_idx = batch_num * FLAGS.batch_size\n",
    "                end_idx = (batch_num + 1) * FLAGS.batch_size\n",
    "                speech_train, label_train = fileh.root.utterance_train[start_idx:end_idx, :, :,\n",
    "                                            :], fileh.root.label_train[start_idx:end_idx]\n",
    "\n",
    "                # This transpose is necessary for 3D convolutional operation which will be performed by TensorFlow.\n",
    "                speech_train = np.transpose(speech_train[None, :, :, :, :], axes=(1, 4, 2, 3, 0))\n",
    "\n",
    "                # shuffling\n",
    "                index = random.sample(range(speech_train.shape[0]), speech_train.shape[0])\n",
    "                speech_train = speech_train[index]\n",
    "                label_train = label_train[index]\n",
    "\n",
    "\n",
    "                _, loss_value, train_accuracy, summary, training_step, _ = sess.run(\n",
    "                    [train_op, loss, accuracy, summary_op, global_step, is_training],\n",
    "                    feed_dict={is_training: True, batch_dynamic: label_train.shape[0], margin_imp_tensor: 100,\n",
    "                               batch_speech: speech_train,\n",
    "                               batch_labels: label_train.reshape([label_train.shape[0], 1])})\n",
    "                summary_writer.add_summary(summary, epoch * num_batches_per_epoch + i)\n",
    "\n",
    "\n",
    "                # # log\n",
    "                if (batch_num + 1) % FLAGS.log_every_n_steps == 0:\n",
    "                    print(\"Epoch \" + str(epoch + 1) + \", Minibatch \" + str(\n",
    "                        batch_num + 1) + \" of %d \" % num_batches_per_epoch + \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss_value) + \", TRAIN ACCURACY= \" + \"{:.3f}\".format(\n",
    "                        100 * train_accuracy))\n",
    "\n",
    "            # Save the model\n",
    "            saver.save(sess, FLAGS.train_dir, global_step=training_step)\n",
    "\n",
    "            # ###################################################\n",
    "            # ############## TEST PER EACH EPOCH ################\n",
    "            # ###################################################\n",
    "\n",
    "            label_vector = np.zeros((FLAGS.batch_size * num_batches_per_epoch_test, 1))\n",
    "            test_accuracy_vector = np.zeros((num_batches_per_epoch_test, 1))\n",
    "\n",
    "            # Loop over all batches\n",
    "            for i in range(num_batches_per_epoch_test):\n",
    "                start_idx = i * FLAGS.batch_size\n",
    "                end_idx = (i + 1) * FLAGS.batch_size\n",
    "                speech_test, label_test = fileh.root.utterance_test[start_idx:end_idx, :, :,\n",
    "                                                           :], fileh.root.label_test[\n",
    "                                                                       start_idx:end_idx]\n",
    "\n",
    "                # Get the test batch.\n",
    "                speech_test = np.transpose(speech_test[None,:,:,:,:],axes=(1,4,2,3,0))\n",
    "\n",
    "                # Evaluation\n",
    "                loss_value, test_accuracy, _ = sess.run([loss, accuracy, is_training],\n",
    "                                                                             feed_dict={is_training: False,\n",
    "                                                                                        batch_dynamic: FLAGS.batch_size,\n",
    "                                                                                        margin_imp_tensor: 50,\n",
    "                                                                                        batch_speech: speech_test,\n",
    "                                                                                        batch_labels: label_test.reshape(\n",
    "                                                                                            [FLAGS.batch_size, 1])})\n",
    "                label_test = label_test.reshape([FLAGS.batch_size, 1])\n",
    "                label_vector[start_idx:end_idx] = label_test\n",
    "                test_accuracy_vector[i, :] = test_accuracy\n",
    "\n",
    "\n",
    "                # ROC\n",
    "\n",
    "                ##############################\n",
    "                ##### K-split validation #####\n",
    "                ##############################\n",
    "            print(\"TESTING after finishing the training on: epoch \" + str(epoch + 1))\n",
    "            # print(\"TESTING accuracy = \", 100 * np.mean(test_accuracy_vector, axis=0))\n",
    "\n",
    "            K = 4\n",
    "            Accuracy = np.zeros((K, 1))\n",
    "            batch_k_validation = int(test_accuracy_vector.shape[0] / float(K))\n",
    "\n",
    "            for i in range(K):\n",
    "                Accuracy[i, :] = 100 * np.mean(test_accuracy_vector[i * batch_k_validation:(i + 1) * batch_k_validation], axis=0)\n",
    "\n",
    "            # Reporting the K-fold validation\n",
    "            print(\"Test Accuracy \" + str(epoch + 1) + \", Mean= \" + \\\n",
    "                          \"{:.4f}\".format(np.mean(Accuracy, axis=0)[0]) + \", std= \" + \"{:.3f}\".format(\n",
    "                        np.std(Accuracy, axis=0)[0]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "import tables\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "import random\n",
    "from nets import nets_factory\n",
    "from auxiliary import losses\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "######################\n",
    "# Train Directory #\n",
    "######################\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'checkpoint_dir', '../../results/TRAIN_CNN_3D',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'evaluation_dataset_path', '../../data/enrollment-evaluation_sample_dataset.hdf5',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'development_dataset_path', '../../data/development_sample_dataset_speaker.hdf5',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'enrollment_dir', '../../results/Model',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'evaluation_dir', '../../results/ROC',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_clones', 1,\n",
    "                            'Number of model clones to deploy.')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('clone_on_cpu', False,\n",
    "                            'Use CPUs to deploy clones.')\n",
    "tf.app.flags.DEFINE_boolean('online_pair_selection', False,\n",
    "                            'Use online pair selection.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('worker_replicas', 1, 'Number of worker replicas.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_ps_tasks', 0,\n",
    "    'The number of parameter servers. If the value is 0, then the parameters '\n",
    "    'are handled locally by the worker.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_readers', 8,\n",
    "    'The number of parallel readers that read data from the dataset.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_preprocessing_threads', 8,\n",
    "    'The number of threads used to create the batches.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'log_every_n_steps', 20,\n",
    "    'The frequency with which logs are print.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'save_summaries_secs', 10,\n",
    "    'The frequency with which summaries are saved, in seconds.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'save_interval_secs', 500,\n",
    "    'The frequency with which the model is saved, in seconds.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'task', 0, 'Task id of the replica running the training.')\n",
    "\n",
    "#######################\n",
    "# Learning Rate Flags #\n",
    "#######################\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'learning_rate_decay_type',\n",
    "    'exponential',\n",
    "    'Specifies how the learning rate is decayed. One of \"fixed\", \"exponential\",'\n",
    "    ' or \"polynomial\"')\n",
    "\n",
    "tf.app.flags.DEFINE_float('learning_rate', 1.0, 'Initial learning rate.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'end_learning_rate', 0.0001,\n",
    "    'The minimal end learning rate used by a polynomial decay learning rate.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'label_smoothing', 0.0, 'The amount of label smoothing.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'learning_rate_decay_factor', 0.94, 'Learning rate decay factor.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'num_epochs_per_decay', 2.0,\n",
    "    'Number of epochs after which learning rate decays.')\n",
    "\n",
    "tf.app.flags.DEFINE_bool(\n",
    "    'sync_replicas', False,\n",
    "    'Whether or not to synchronize the replicas during training.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'replicas_to_aggregate', 1,\n",
    "    'The Number of gradients to collect before updating params.')\n",
    "\n",
    "tf.app.flags.DEFINE_float(\n",
    "    'moving_average_decay', None,\n",
    "    'The decay to use for the moving average.'\n",
    "    'If left as None, then moving averages are not used.')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'model_speech', 'cnn_speech', 'The name of the architecture to train.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'batch_size', 1, 'The number of samples in each batch.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_epochs', 50, 'The number of epochs for training.')\n",
    "\n",
    "# Store all elemnts in FLAG structure!\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Load the artificial datasets.\n",
    "fileh = tables.open_file(FLAGS.evaluation_dataset_path, mode='r')\n",
    "fileh_development = tables.open_file(FLAGS.development_dataset_path, mode='r')\n",
    "# Train\n",
    "print(\"Enrollment data shape:\", fileh.root.utterance_enrollment.shape)\n",
    "print(\"Enrollment label shape:\", fileh.root.label_enrollment.shape)\n",
    "\n",
    "# Test\n",
    "print(\"Evaluation data shape:\", fileh.root.utterance_evaluation.shape)\n",
    "print(\"Evaluation label shape:\",fileh.root.label_evaluation.shape)\n",
    "\n",
    "# Get the number of subjects\n",
    "num_subjects_development = len(np.unique(fileh_development.root.label_train[:]))\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # if not FLAGS.dataset_dir:\n",
    "    #     raise ValueError('You must supply the dataset directory with --dataset_dir')\n",
    "\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default(), tf.device('/cpu:0'):\n",
    "\n",
    "        # required from data\n",
    "        num_samples_per_epoch = fileh.root.label_enrollment.shape[0]\n",
    "        num_batches_per_epoch = int(num_samples_per_epoch / FLAGS.batch_size)\n",
    "\n",
    "        num_samples_per_epoch_test = fileh.root.label_evaluation.shape[0]\n",
    "        num_batches_per_epoch_test = int(num_samples_per_epoch_test / FLAGS.batch_size)\n",
    "\n",
    "        # Create global_step\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "        ######################\n",
    "        # Select the network #\n",
    "        ######################\n",
    "\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        model_speech_fn = nets_factory.get_network_fn(\n",
    "            FLAGS.model_speech,\n",
    "            num_classes=num_subjects_development,\n",
    "            is_training=is_training)\n",
    "\n",
    "        ##############################################################\n",
    "        # Create a dataset provider that loads data from the dataset #\n",
    "        ##############################################################\n",
    "        # with tf.device(deploy_config.inputs_device()):\n",
    "        \"\"\"\n",
    "        Define the place holders and creating the batch tensor.\n",
    "        \"\"\"\n",
    "        speech = tf.placeholder(tf.float32, (20, 80, 40, 1))\n",
    "        label = tf.placeholder(tf.int32, (1))\n",
    "        batch_dynamic = tf.placeholder(tf.int32, ())\n",
    "        margin_imp_tensor = tf.placeholder(tf.float32, ())\n",
    "\n",
    "        # Create the batch tensors\n",
    "        batch_speech, batch_labels = tf.train.batch(\n",
    "            [speech, label],\n",
    "            batch_size=batch_dynamic,\n",
    "            num_threads=FLAGS.num_preprocessing_threads,\n",
    "            capacity=5 * FLAGS.batch_size)\n",
    "\n",
    "        #############################\n",
    "        # Specify the loss function #\n",
    "        #############################\n",
    "        tower_grads = []\n",
    "        with tf.variable_scope(tf.get_variable_scope()):\n",
    "            for i in xrange(FLAGS.num_clones):\n",
    "                with tf.device('/gpu:%d' % i):\n",
    "                    with tf.name_scope('%s_%d' % ('tower', i)) as scope:\n",
    "                        \"\"\"\n",
    "                        Two distance metric are defined:\n",
    "                           1 - distance_weighted: which is a weighted average of the distance between two structures.\n",
    "                           2 - distance_l2: which is the regular l2-norm of the two networks outputs.\n",
    "                        Place holders\n",
    "\n",
    "                        \"\"\"\n",
    "                        ########################################\n",
    "                        ######## Outputs of two networks #######\n",
    "                        ########################################\n",
    "                        # step = int(FLAGS.batch_size / float(FLAGS.num_clones))\n",
    "                        # logits, end_points_speech = model_speech_fn(batch_speech[i * step : (i + 1) * step])\n",
    "                        features, logits, end_points_speech = model_speech_fn(batch_speech)\n",
    "\n",
    "                        # # Uncomment if the output embedding is desired to be as |f(x)| = 1\n",
    "                        # logits_speech = tf.nn.l2_normalize(logits_speech, dim=1, epsilon=1e-12, name=None)\n",
    "                        # logits_mouth = tf.nn.l2_normalize(logits_mouth, dim=1, epsilon=1e-12, name=None)\n",
    "\n",
    "                        #######################################################\n",
    "                        ################# Distance Calculation ################\n",
    "                        #######################################################\n",
    "\n",
    "                        # ##### Weighted distance using a fully connected layer #####\n",
    "                        # distance_vector = tf.abs(tf.subtract(logits_speech_L, logits_speech_R, name=None))\n",
    "                        # logits = slim.fully_connected(distance_vector, 2, normalizer_fn=None, activation_fn=None,\n",
    "                        #                               scope='fc_weighted')\n",
    "\n",
    "                        ###############################################\n",
    "                        ########## Loss function ##########\n",
    "                        ###############################################\n",
    "\n",
    "                        # one_hot labeling\n",
    "                        label_onehot = tf.one_hot(tf.squeeze(batch_labels, [1]), depth=num_subjects_development, axis=-1)\n",
    "\n",
    "                        # Define loss\n",
    "                        with tf.name_scope('loss'):\n",
    "                            loss = tf.reduce_mean(\n",
    "                                tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_onehot))\n",
    "\n",
    "                        # Accuracy\n",
    "                        with tf.name_scope('accuracy'):\n",
    "                            # Evaluate the model\n",
    "                            correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(label_onehot, 1))\n",
    "\n",
    "                            # Accuracy calculation\n",
    "                            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "                            # # ##### call the optimizer ######\n",
    "                            # # # TODO: call optimizer object outside of this gpu environment\n",
    "                            # #\n",
    "                            # # Reuse variables for the next tower.\n",
    "                            # tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "        #################################################\n",
    "        ########### Summary Section #####################\n",
    "        #################################################\n",
    "\n",
    "        # Gather initial summaries.\n",
    "        summaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))\n",
    "\n",
    "        # Add summaries for all end_points.\n",
    "        for end_point in end_points_speech:\n",
    "            x = end_points_speech[end_point]\n",
    "            summaries.add(tf.summary.scalar('sparsity_speech/' + end_point,\n",
    "                                            tf.nn.zero_fraction(x)))\n",
    "\n",
    "            # for end_point in end_points_speech_R:\n",
    "            #     x = end_points_speech_R[end_point]\n",
    "            #     summaries.add(tf.summary.scalar('sparsity_mouth/' + end_point,\n",
    "            #                                     tf.nn.zero_fraction(x)))\n",
    "\n",
    "            # # Add summaries for variables.\n",
    "            # for variable in slim.get_model_variables():\n",
    "            #     summaries.add(tf.summary.histogram(variable.op.name, variable))\n",
    "            #\n",
    "            # # # Add to parameters to summaries\n",
    "            # # summaries.add(tf.summary.scalar('learning_rate', learning_rate))\n",
    "            # # summaries.add(tf.summary.scalar('global_step', global_step))\n",
    "            # # summaries.add(tf.summary.scalar('eval/Loss', loss))\n",
    "            # # summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES))\n",
    "            #\n",
    "            # # Merge all summaries together.\n",
    "            # summary_op = tf.summary.merge(list(summaries), name='summary_op')\n",
    "\n",
    "    ###########################\n",
    "    ######## ######## #########\n",
    "    ###########################\n",
    "\n",
    "    with tf.Session(graph=graph, config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "\n",
    "        # Initialization of the network.\n",
    "        variables_to_restore = slim.get_variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore, max_to_keep=20)\n",
    "        coord = tf.train.Coordinator()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        ################################################\n",
    "        ############## ENROLLMENT Model ################\n",
    "        ################################################\n",
    "\n",
    "        latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir=FLAGS.checkpoint_dir)\n",
    "        saver.restore(sess, latest_checkpoint)\n",
    "\n",
    "        speaker_model_path = os.path.join(FLAGS.enrollment_dir,'MODEL.npy')\n",
    "        MODEL = np.load(speaker_model_path)\n",
    "\n",
    "\n",
    "\n",
    "        feature_vector = np.zeros((num_batches_per_epoch_test*FLAGS.batch_size, 128))\n",
    "        label_vector = np.zeros((num_batches_per_epoch_test * FLAGS.batch_size, 1))\n",
    "\n",
    "        step = 1\n",
    "        # Loop over all batches\n",
    "        for batch_num in range(num_batches_per_epoch_test):\n",
    "\n",
    "            step += 1\n",
    "            start_idx = batch_num * FLAGS.batch_size\n",
    "            end_idx = (batch_num + 1) * FLAGS.batch_size\n",
    "            speech_evaluation, label_evaluation = fileh.root.utterance_evaluation[start_idx:end_idx, :, :,\n",
    "                                                  0:1], fileh.root.label_evaluation[start_idx:end_idx]\n",
    "\n",
    "            # Copy to match dimension\n",
    "            speech_evaluation = np.repeat(speech_evaluation,20,axis=3)\n",
    "            speech_evaluation = np.transpose(speech_evaluation[None, :, :, :, :], axes=(1, 4, 2, 3, 0))\n",
    "\n",
    "\n",
    "            feature = sess.run(\n",
    "                [features],\n",
    "                feed_dict={is_training: True, batch_dynamic: label_evaluation.shape[0],\n",
    "                           batch_speech: speech_evaluation,\n",
    "                           batch_labels: label_evaluation.reshape([label_evaluation.shape[0], 1])})\n",
    "\n",
    "            # Extracting the associated numpy array.\n",
    "            feature_speaker = feature[0]\n",
    "\n",
    "            # # # L2-norm along each utterance vector\n",
    "            # feature_speaker = sklearn.preprocessing.normalize(feature_speaker, norm='l2', axis=1, copy=True,\n",
    "            #                                                   return_norm=False)\n",
    "\n",
    "            feature_vector[start_idx:end_idx,:] = feature_speaker\n",
    "            label_vector[start_idx:end_idx,:] = label_evaluation.reshape([label_evaluation.shape[0], 1])\n",
    "\n",
    "\n",
    "        ########################################\n",
    "        ########## SCORE COMPUTATION ###########\n",
    "        ########################################\n",
    "        NumClasses = MODEL.shape[0]\n",
    "        NumFeatures = MODEL.shape[1]\n",
    "        score_vector = np.zeros((feature_vector.shape[0]*NumClasses, 1))\n",
    "        target_label_vector = np.zeros((feature_vector.shape[0]*NumClasses, 1))\n",
    "\n",
    "\n",
    "        for i in range(feature_vector.shape[0]):\n",
    "            if i % 100 ==0:\n",
    "                print(\"processing file %d from %d\" %(i,feature_vector.shape[0]))\n",
    "            for j in range(NumClasses):\n",
    "                model = MODEL[j:j+1, :]\n",
    "                score = cosine_similarity(feature_vector[i:i+1,:], model)\n",
    "                score_vector[i*NumClasses + j] = score\n",
    "                # print(score)\n",
    "                if (j+1) == label_vector[i,:]:\n",
    "                    target_label_vector[i*NumClasses + j] = 1\n",
    "                else:\n",
    "                    target_label_vector[i * NumClasses + j] = 0\n",
    "\n",
    "        # Save the score and label vector.\n",
    "        if not os.path.exists(FLAGS.evaluation_dir):\n",
    "            os.makedirs(FLAGS.evaluation_dir)\n",
    "        np.save(os.path.join(FLAGS.evaluation_dir,'score_vector.npy'),score_vector)\n",
    "        np.save(os.path.join(FLAGS.evaluation_dir,'target_label_vector.npy'),target_label_vector)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c3b7e4744ad9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m tf.app.flags.DEFINE_string(\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Siamese Architecture for face recognition\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pdb\n",
    "import sys\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'evaluation_dir', '../../results/ROC',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "\n",
    "# Store all elemnts in FLAG structure!\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "score = np.load(os.path.join(FLAGS.evaluation_dir,'score_vector.npy'))\n",
    "label = np.load(os.path.join(FLAGS.evaluation_dir,'target_label_vector.npy'))\n",
    "\n",
    "\n",
    "def calculate_eer_auc_ap(label,distance):\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, distance, pos_label=1)\n",
    "    AUC = metrics.roc_auc_score(label, distance, average='macro', sample_weight=None)\n",
    "    AP = metrics.average_precision_score(label, distance, average='macro', sample_weight=None)\n",
    "\n",
    "    # Calculating EER\n",
    "    intersect_x = fpr[np.abs(fpr - (1 - tpr)).argmin(0)]\n",
    "    EER = intersect_x\n",
    "\n",
    "    return EER,AUC,AP,fpr, tpr\n",
    "\n",
    "# K-fold validation for ROC\n",
    "k=1\n",
    "step = int(label.shape[0] / float(k))\n",
    "EER_VECTOR = np.zeros((k,1))\n",
    "AUC_VECTOR = np.zeros((k,1))\n",
    "for split_num in range(k):\n",
    "    index_start = split_num * step\n",
    "    index_end = (split_num + 1) * step\n",
    "    EER_temp,AUC_temp,AP,fpr, tpr = calculate_eer_auc_ap(label[index_start:index_end],score[index_start:index_end])\n",
    "    EER_VECTOR[split_num] = EER_temp * 100\n",
    "    AUC_VECTOR[split_num] = AUC_temp * 100\n",
    "\n",
    "print(\"EER=\",np.mean(EER_VECTOR),np.std(EER_VECTOR))\n",
    "print(\"AUC=\",np.mean(AUC_VECTOR),np.std(AUC_VECTOR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese Architecture for face recognition\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pdb\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def Plot_HIST_Fn(label,distance, save_path, num_bins = 50):\n",
    "\n",
    "    dissimilarity = distance[:]\n",
    "    gen_dissimilarity_original = []\n",
    "    imp_dissimilarity_original = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 1:\n",
    "            gen_dissimilarity_original.append(dissimilarity[i])\n",
    "        else:\n",
    "            imp_dissimilarity_original.append(dissimilarity[i])\n",
    "\n",
    "    bins = np.linspace(np.amin(distance), np.amax(distance), num_bins)\n",
    "    fig = plt.figure()\n",
    "    plt.hist(gen_dissimilarity_original, bins, alpha=0.5, facecolor='blue', normed=False, label='gen_dist_original')\n",
    "    plt.hist(imp_dissimilarity_original, bins, alpha=0.5, facecolor='red', normed=False, label='imp_dist_original')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('OriginalFeatures_Histogram.jpg')\n",
    "    plt.show()\n",
    "    fig.savefig(save_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    tf.app.flags.DEFINE_string(\n",
    "    'evaluation_dir', '../../results/SCORES',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "    \n",
    "    tf.app.flags.DEFINE_string(\n",
    "    'plot_dir', '../../results/PLOTS',\n",
    "    'Directory where plots are saved to.')\n",
    "    \n",
    "    tf.app.flags.DEFINE_integer(\n",
    "    'num_bins', '50',\n",
    "    'Number of bins for plotting histogram.')\n",
    "\n",
    "    # Store all elemnts in FLAG structure!\n",
    "    FLAGS = tf.app.flags.FLAGS\n",
    "    \n",
    "    # Loading necessary data.\n",
    "    score = np.load(os.path.join(FLAGS.evaluation_dir,'score_vector.npy'))\n",
    "    label = np.load(os.path.join(FLAGS.evaluation_dir,'target_label_vector.npy'))\n",
    "    save_path = os.path.join(FLAGS.plot_dir,'Histogram.jpg')\n",
    "    \n",
    "    # Creating the path\n",
    "    if not os.path.exists(FLAGS.plot_dir):\n",
    "            os.makedirs(FLAGS.plot_dir)\n",
    "            \n",
    "    Plot_HIST_Fn(label,score, save_path, FLAGS.num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese Architecture for face recognition\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pdb\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def Plot_PR_Fn(label,distance,phase):\n",
    "\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(label, distance, pos_label=1, sample_weight=None)\n",
    "    AP = metrics.average_precision_score(label, distance, average='macro', sample_weight=None)\n",
    "\n",
    "    # AP(average precision) calculation.\n",
    "    # This score corresponds to the area under the precision-recall curve.\n",
    "    print(\"AP = \", float((\"{0:.%ie}\" % 1).format(AP)))\n",
    "\n",
    "    # Plot the ROC\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    lines = plt.plot(recall, precision, label='ROC Curve')\n",
    "    plt.setp(lines, linewidth=2, color='r')\n",
    "    ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title(phase + '_' + 'PR.jpg')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "\n",
    "    # Cutting the floating number\n",
    "    AP = '%.2f' % AP\n",
    "\n",
    "    # Setting text to plot\n",
    "    # plt.text(0.5, 0.5, 'AP = ' + str(AP), fontdict=None)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    fig.savefig(save_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    tf.app.flags.DEFINE_string(\n",
    "    'evaluation_dir', '../../results/SCORES',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "    \n",
    "    tf.app.flags.DEFINE_string(\n",
    "    'plot_dir', '../../results/PLOTS',\n",
    "    'Directory where plots are saved to.')\n",
    "\n",
    "    # Store all elemnts in FLAG structure!\n",
    "    FLAGS = tf.app.flags.FLAGS\n",
    "    \n",
    "    # Loading necessary data.\n",
    "    score = np.load(os.path.join(FLAGS.evaluation_dir,'score_vector.npy'))\n",
    "    label = np.load(os.path.join(FLAGS.evaluation_dir,'target_label_vector.npy'))\n",
    "    save_path = os.path.join(FLAGS.plot_dir,'PR.jpg')\n",
    "    \n",
    "    # Creating the path\n",
    "    if not os.path.exists(FLAGS.plot_dir):\n",
    "            os.makedirs(FLAGS.plot_dir)\n",
    "            \n",
    "    Plot_PR_Fn(label,score,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese Architecture for face recognition\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pdb\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def Plot_ROC_Fn(label,distance,save_path):\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, distance, pos_label=1)\n",
    "    AUC = metrics.roc_auc_score(label, distance, average='macro', sample_weight=None)\n",
    "    # AP = metrics.average_precision_score(label, -distance, average='macro', sample_weight=None)\n",
    "\n",
    "    # Calculating EER\n",
    "    intersect_x = fpr[np.abs(fpr - (1 - tpr)).argmin(0)]\n",
    "    EER = intersect_x\n",
    "    print(\"EER = \", float((\"{0:.%ie}\" % 1).format(intersect_x)))\n",
    "\n",
    "    # AUC(area under the curve) calculation\n",
    "    print(\"AUC = \", float((\"{0:.%ie}\" % 1).format(AUC)))\n",
    "\n",
    "    # # AP(average precision) calculation.\n",
    "    # # This score corresponds to the area under the precision-recall curve.\n",
    "    # print(\"AP = \", float((\"{0:.%ie}\" % 1).format(AP)))\n",
    "\n",
    "    # Plot the ROC\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    lines = plt.plot(fpr, tpr, label='ROC Curve')\n",
    "    plt.setp(lines, linewidth=2, color='r')\n",
    "    ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title('ROC.jpg')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    # # Cutting the floating number\n",
    "    # AUC = '%.2f' % AUC\n",
    "    # EER = '%.2f' % EER\n",
    "    # # AP = '%.2f' % AP\n",
    "    #\n",
    "    # # Setting text to plot\n",
    "    # # plt.text(0.5, 0.6, 'AP = ' + str(AP), fontdict=None)\n",
    "    # plt.text(0.5, 0.5, 'AUC = ' + str(AUC), fontdict=None)\n",
    "    # plt.text(0.5, 0.4, 'EER = ' + str(EER), fontdict=None)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    fig.savefig(save_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    tf.app.flags.DEFINE_string(\n",
    "    'evaluation_dir', '../../results/SCORES',\n",
    "    'Directory where checkpoints and event logs are written to.')\n",
    "    \n",
    "    tf.app.flags.DEFINE_string(\n",
    "    'plot_dir', '../../results/PLOTS',\n",
    "    'Directory where plots are saved to.')\n",
    "\n",
    "    # Store all elemnts in FLAG structure!\n",
    "    FLAGS = tf.app.flags.FLAGS\n",
    "    \n",
    "    # Loading scores and labels\n",
    "    score = np.load(os.path.join(FLAGS.evaluation_dir,'score_vector.npy'))\n",
    "    label = np.load(os.path.join(FLAGS.evaluation_dir,'target_label_vector.npy'))\n",
    "    save_path = os.path.join(FLAGS.plot_dir,'ROC.jpg')\n",
    "    \n",
    "    # Creating the path\n",
    "    if not os.path.exists(FLAGS.plot_dir):\n",
    "            os.makedirs(FLAGS.plot_dir)\n",
    "            \n",
    "    Plot_ROC_Fn(label,score,save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sv",
   "language": "python",
   "name": "sv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
